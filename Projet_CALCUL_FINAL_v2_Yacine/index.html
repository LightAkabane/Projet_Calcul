<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>WebGPU Person Detector - YOLO + OSNet</title>
  <style>
    body {
      margin: 0;
      background: #111;
      color: #eee;
      font-family: system-ui, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 10px;
    }

    #container {
      position: relative;
      width: 640px;
      height: 480px;
      margin-top: 20px;
      border: 2px solid #444;
      border-radius: 8px;
      overflow: hidden;
      background: #000;
    }

    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    #status {
      margin-top: 10px;
      font-size: 14px;
      color: #aaa;
    }

    #counter, #unique-counter {
      margin-top: 5px;
      font-size: 16px;
      font-weight: 600;
    }

    #counter {
      color: #4ade80; /* vert */
    }

    #unique-counter {
      color: #60a5fa; /* bleu */
    }
  </style>

  <!-- ONNX Runtime Web (inclut support WebGPU si dispo) -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
  <h1>WebGPU Person Detector + OSNet Re-ID</h1>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="overlay"></canvas>
  </div>
  <div id="status">Initialisation...</div>
  <div id="counter">Personnes détectées : 0</div>
  <div id="unique-counter">Personnes uniques vues : 0</div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const counterEl = document.getElementById('counter');
    const uniqueCounterEl = document.getElementById('unique-counter');

    // Tracking (court terme)
    let tracks = [];
    let nextTrackId = 1;

    // Galerie d'identités Re-ID (long terme)
    let identities = [];
    let nextIdentityId = 1;

    const MAX_MISSED_FRAMES = 20;
    const MIN_HITS = 5;

    // Taille d'entrée du modèle YOLO
    const MODEL_WIDTH = 640;
    const MODEL_HEIGHT = 640;

    const offscreenCanvas = document.createElement('canvas');
    offscreenCanvas.width = MODEL_WIDTH;
    offscreenCanvas.height = MODEL_HEIGHT;
    const offscreenCtx = offscreenCanvas.getContext('2d', { willReadFrequently: true });

    // OSNet Re-ID (ton modèle attend 256x128 mais en (H, W))
    const REID_HEIGHT = 256;
    const REID_WIDTH = 128;

    const reidCanvas = document.createElement('canvas');
    reidCanvas.width = REID_WIDTH;
    reidCanvas.height = REID_HEIGHT;
    const reidCtx = reidCanvas.getContext('2d', { willReadFrequently: true });

    // Sessions ONNX
    let session = null;
    let inputName = null;

    let reidSession = null;
    let reidInputName = null;
    let reidOutputName = null;

    async function initCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 }
        });
        video.srcObject = stream;

        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            resolve();
          };
        });
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'Erreur accès caméra : ' + err.message;
      }
    }

    async function initOrt() {
      if (!('gpu' in navigator)) {
        statusEl.textContent = 'WebGPU non disponible dans ce navigateur (essaie Chrome/Edge récent avec WebGPU activé).';
        throw new Error('WebGPU not supported');
      }

      statusEl.textContent = 'Initialisation des modèles (YOLO + OSNet Re-ID)...';

      try {
        // YOLO pour la détection
        session = await ort.InferenceSession.create('yolov8n.onnx', {
          executionProviders: ['webgpu', 'wasm']
        });
        inputName = session.inputNames[0];
        console.log('Session YOLO initialisée, input =', inputName);
      } catch (e) {
        console.error('Erreur init YOLO:', e);
        throw e;
      }

      try {
        // Re-ID : OSNet pour extraction de features de personne
        // OSNet x0_25: input 256x128, output feature vector
        reidSession = await ort.InferenceSession.create('osnet_reid.onnx', {
          executionProviders: ['wasm']
        });
        reidInputName = reidSession.inputNames[0];
        reidOutputName = reidSession.outputNames[0];
        console.log('Session OSNet Re-ID initialisée, input =', reidInputName, 'output =', reidOutputName);
      } catch (e) {
        console.error('Erreur init OSNet Re-ID:', e);
        statusEl.textContent = 'YOLO OK, mais OSNet Re-ID non initialisé (voir console).';
        reidSession = null;
      }
    }

    function cosineSimilarity(a, b) {
      let dot = 0;
      let na = 0;
      let nb = 0;
      for (let i = 0; i < a.length; i++) {
        const va = a[i];
        const vb = b[i];
        dot += va * vb;
        na += va * va;
        nb += vb * vb;
      }
      if (na === 0 || nb === 0) return 0;
      return dot / (Math.sqrt(na) * Math.sqrt(nb));
    }

    // Attribution d'une identité globale (pour le compteur "uniques vues")
    function assignIdentityToTrack(track) {
      if (!track.embedding) return;

      // OSNet est plus précis, on peut baisser le threshold
      const IDENTITY_THRESHOLD = 0.71;

      let bestIdentity = null;
      let bestSim = -1;

      for (const ident of identities) {
        const sim = cosineSimilarity(track.embedding, ident.embedding);
        if (sim > bestSim) {
          bestSim = sim;
          bestIdentity = ident;
        }
      }

      if (bestIdentity && bestSim >= IDENTITY_THRESHOLD) {
        track.identityId = bestIdentity.id;

        // Mise à jour EMA de l'embedding de l'identité
        const emb = bestIdentity.embedding;
        const newEmb = track.embedding;
        for (let i = 0; i < emb.length; i++) {
          emb[i] = 0.7 * newEmb[i] + 0.3 * emb[i];
        }
      } else {
        // Nouvelle identité
        const id = nextIdentityId++;
        track.identityId = id;
        identities.push({
          id,
          embedding: track.embedding.slice()
        });
      }
    }

    function preprocessReid(det) {
      // Recadrer la personne dans 256x128 (format OSNet)
      reidCtx.clearRect(0, 0, REID_WIDTH, REID_HEIGHT);

      reidCtx.drawImage(
        video,
        det.x, det.y, det.w, det.h,
        0, 0, REID_WIDTH, REID_HEIGHT
      );

      const imageData = reidCtx.getImageData(0, 0, REID_WIDTH, REID_HEIGHT);
      const data = imageData.data;

      const float32Data = new Float32Array(3 * REID_WIDTH * REID_HEIGHT);
      const size = REID_WIDTH * REID_HEIGHT;

      // Normalisation ImageNet classique
      const mean = [0.485, 0.456, 0.406];
      const std  = [0.229, 0.224, 0.225];

      for (let i = 0; i < size; i++) {
        const r = data[4 * i] / 255;
        const g = data[4 * i + 1] / 255;
        const b = data[4 * i + 2] / 255;

        float32Data[i]           = (r - mean[0]) / std[0];         // R
        float32Data[i + size]    = (g - mean[1]) / std[1];         // G
        float32Data[i + 2*size]  = (b - mean[2]) / std[2];         // B
      }

      return new ort.Tensor('float32', float32Data, [1, 3, REID_HEIGHT, REID_WIDTH]);
    }

    async function extractReidEmbedding(det) {
      if (!reidSession) return null;

      try {
        const inputTensor = preprocessReid(det);
        const feeds = {};
        feeds[reidInputName] = inputTensor;

        const results = await reidSession.run(feeds);
        const output = results[reidOutputName];

        // OSNet output: feature vector (généralement 512D ou similaire)
        const embedding = output.data; // Float32Array

        // Normalisation L2 pour cosine similarity
        let norm = 0;
        for (let i = 0; i < embedding.length; i++) {
          norm += embedding[i] * embedding[i];
        }
        norm = Math.sqrt(norm) || 1;

        const normalized = new Float32Array(embedding.length);
        for (let i = 0; i < embedding.length; i++) {
          normalized[i] = embedding[i] / norm;
        }

        return normalized;
      } catch (e) {
        console.error('Erreur OSNet Re-ID sur une détection:', e);
        return null;
      }
    }

    function preprocess() {
      offscreenCtx.drawImage(video, 0, 0, MODEL_WIDTH, MODEL_HEIGHT);
      const imageData = offscreenCtx.getImageData(0, 0, MODEL_WIDTH, MODEL_HEIGHT);
      const { data } = imageData;

      const float32Data = new Float32Array(3 * MODEL_WIDTH * MODEL_HEIGHT);
      const size = MODEL_WIDTH * MODEL_HEIGHT;

      for (let i = 0; i < size; i++) {
        const r = data[4 * i] / 255;
        const g = data[4 * i + 1] / 255;
        const b = data[4 * i + 2] / 255;

        float32Data[i] = r;
        float32Data[i + size] = g;
        float32Data[i + 2 * size] = b;
      }

      const tensor = new ort.Tensor('float32', float32Data, [1, 3, MODEL_HEIGHT, MODEL_WIDTH]);
      return tensor;
    }

    function iou(boxA, boxB) {
      const xA = Math.max(boxA.x1, boxB.x1);
      const yA = Math.max(boxA.y1, boxB.y1);
      const xB = Math.min(boxA.x2, boxB.x2);
      const yB = Math.min(boxA.y2, boxB.y2);

      const interW = Math.max(0, xB - xA);
      const interH = Math.max(0, yB - yA);
      const interArea = interW * interH;

      const boxAArea = (boxA.x2 - boxA.x1) * (boxA.y2 - boxA.y1);
      const boxBArea = (boxB.x2 - boxB.x1) * (boxB.y2 - boxB.y1);

      const union = boxAArea + boxBArea - interArea;
      if (union <= 0) return 0;
      return interArea / union;
    }

    function nonMaxSuppression(boxes, iouThreshold = 0.45) {
      const sorted = boxes.slice().sort((a, b) => b.score - a.score);
      const result = [];

      while (sorted.length > 0) {
        const candidate = sorted.shift();
        result.push(candidate);

        for (let i = sorted.length - 1; i >= 0; i--) {
          if (iou(candidate, sorted[i]) > iouThreshold) {
            sorted.splice(i, 1);
          }
        }
      }
      return result;
    }

    function updateTracks(detections) {
      tracks.forEach(t => { t.matched = false; });

      const IOU_MATCH_THRESHOLD = 0.3;

      detections.forEach(det => {
        const detBox = {
          x1: det.x,
          y1: det.y,
          x2: det.x + det.w,
          y2: det.y + det.h
        };

        let bestTrack = null;
        let bestIoU = 0;

        tracks.forEach(track => {
          const trackBox = {
            x1: track.x,
            y1: track.y,
            x2: track.x + track.w,
            y2: track.y + track.h
          };

          const iouVal = iou(detBox, trackBox);
          if (iouVal > bestIoU) {
            bestIoU = iouVal;
            bestTrack = track;
          }
        });

        if (bestTrack && bestIoU > IOU_MATCH_THRESHOLD) {
          const alpha = 0.7;
          bestTrack.x = alpha * det.x + (1 - alpha) * bestTrack.x;
          bestTrack.y = alpha * det.y + (1 - alpha) * bestTrack.y;
          bestTrack.w = alpha * det.w + (1 - alpha) * bestTrack.w;
          bestTrack.h = alpha * det.h + (1 - alpha) * bestTrack.h;

          if (det.embedding) {
            bestTrack.embedding = det.embedding.slice();
          }

          bestTrack.missed = 0;
          bestTrack.hits = (bestTrack.hits || 0) + 1;
          bestTrack.matched = true;

          if (!bestTrack.confirmed && bestTrack.hits >= MIN_HITS) {
            bestTrack.confirmed = true;
            assignIdentityToTrack(bestTrack);
          }

          det.id = bestTrack.confirmed ? bestTrack.id : null;
        } else {
          const newTrack = {
            id: nextTrackId++,
            x: det.x,
            y: det.y,
            w: det.w,
            h: det.h,
            missed: 0,
            hits: 1,
            confirmed: false,
            matched: true,
            embedding: det.embedding ? det.embedding.slice() : null,
            identityId: null
          };
          tracks.push(newTrack);
          det.id = null;
        }
      });

      tracks = tracks.filter(track => {
        if (!track.matched) {
          track.missed = (track.missed || 0) + 1;
        }
        return track.missed <= MAX_MISSED_FRAMES;
      });

      return detections;
    }

    function postprocess(output) {
      const data = output.data;
      const dims = output.dims;

      const batch = dims[0];
      const channels = dims[1];
      const numAnchors = dims[2];

      const numClasses = channels - 4;
      const boxes = [];
      const confThreshold = 0.6;

      for (let i = 0; i < numAnchors; i++) {
        const cx = data[0 * numAnchors + i];
        const cy = data[1 * numAnchors + i];
        const w  = data[2 * numAnchors + i];
        const h  = data[3 * numAnchors + i];

        if (w <= 0 || h <= 0) continue;

        let bestScore = -Infinity;
        let bestClass = -1;

        for (let c = 0; c < numClasses; c++) {
          const score = data[(4 + c) * numAnchors + i];
          if (score > bestScore) {
            bestScore = score;
            bestClass = c;
          }
        }

        const prob = bestScore;

        if (bestClass !== 0 || prob < confThreshold) continue;

        let x1 = (cx - w / 2) / MODEL_WIDTH;
        let y1 = (cy - h / 2) / MODEL_HEIGHT;
        let x2 = (cx + w / 2) / MODEL_WIDTH;
        let y2 = (cy + h / 2) / MODEL_HEIGHT;

        if (x2 <= x1 || y2 <= y1) continue;
        if (x2 < 0 || y2 < 0 || x1 > 1 || y1 > 1) continue;

        x1 = Math.max(0, Math.min(1, x1));
        y1 = Math.max(0, Math.min(1, y1));
        x2 = Math.max(0, Math.min(1, x2));
        y2 = Math.max(0, Math.min(1, y2));

        boxes.push({
          x1,
          y1,
          x2,
          y2,
          score: prob,
          classId: bestClass
        });
      }

      const nmsBoxes = nonMaxSuppression(boxes, 0.45);

      return nmsBoxes.map(b => ({
        x: b.x1 * canvas.width,
        y: b.y1 * canvas.height,
        w: (b.x2 - b.x1) * canvas.width,
        h: (b.y2 - b.y1) * canvas.height,
        score: b.score
      }));
    }
    
    function drawDetections(detections) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      ctx.lineWidth = 2;
      ctx.font = '16px system-ui';

      detections.forEach(det => {
        ctx.strokeStyle = 'lime';
        ctx.fillStyle = 'lime';

        ctx.strokeRect(det.x, det.y, det.w, det.h);
        const idText = det.id != null ? `ID ${det.id}` : '';
        const label = `Person ${(det.score * 100).toFixed(1)}%`;
        const textX = det.x + 4;
        const textY = det.y - 6;

        ctx.fillText(label, textX, textY < 12 ? 12 : textY);
      });
    }

    async function runDetectionOnce() {
      if (!session) return;

      const inputTensor = preprocess();
      const feeds = {};
      feeds[inputName] = inputTensor;

      const results = await session.run(feeds);
      const outputName = session.outputNames[0];
      const output = results[outputName];

      let detections = postprocess(output);

      // Embedding Re-ID via OSNet pour toutes les personnes détectées
      if (reidSession) {
        for (const det of detections) {
          det.embedding = await extractReidEmbedding(det);
        }
      } else {
        for (const det of detections) {
          det.embedding = null;
        }
      }

      // Tracking + identités globales
      detections = updateTracks(detections);

      const activeDetections = detections.filter(det => det.id != null);

      if (counterEl) {
        counterEl.textContent = `Personnes détectées : ${activeDetections.length}`;
      }
      if (uniqueCounterEl) {
        uniqueCounterEl.textContent = `Personnes uniques vues : ${identities.length}`;
      }

      drawDetections(activeDetections);
    }

    let isRunning = false;

    async function detectionLoop() {
      if (!isRunning) return;

      await runDetectionOnce();
      requestAnimationFrame(detectionLoop);
    }

    (async () => {
      try {
        statusEl.textContent = 'Demande daccès à la caméra...';
        await initCamera();
        statusEl.textContent = 'Caméra OK. Initialisation WebGPU / modèles...';

        await initOrt();

        statusEl.textContent = 'Modèles chargés, détection en cours...';
        isRunning = true;
        detectionLoop();
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'Erreur initialisation : ' + err.message;
      }
    })();
  </script>
</body>
</html>